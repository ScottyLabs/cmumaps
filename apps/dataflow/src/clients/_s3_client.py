import json
import os
from functools import lru_cache
from pathlib import Path
from typing import Any, cast

from minio import Minio
from pydantic import BaseModel, ValidationError

from logger import get_app_logger
from models import Buildings, Floorplans, Graph, Placements

# Mapping of S3 object name patterns to their Pydantic validator models
SCHEMA_VALIDATORS: dict[str, type[BaseModel]] = {
    "buildings.json": Buildings,
    "floorplans.json": Floorplans,
    "placements.json": Placements,
    "all-graph.json": Graph,
}


@lru_cache(maxsize=1)
def get_s3_client_singleton() -> S3Client:
    return S3Client()


class S3Client:
    BUCKET_NAME = "cmumaps"

    def __init__(self) -> None:
        self.logger = get_app_logger()

        self.access_key = os.getenv("S3_ACCESS_KEY")
        self.secret_key = os.getenv("S3_SECRET_KEY")
        self.s3_endpoint = os.getenv("S3_ENDPOINT")

        if not self.s3_endpoint:
            msg = "S3_ENDPOINT must be set"
            self.logger.critical(msg)
            raise ValueError(msg)

        self._client = Minio(
            self.s3_endpoint,
            access_key=self.access_key,
            secret_key=self.secret_key,
        )

        self.logger = get_app_logger()

    def _get_validator(self, s3_object_name: str) -> type[BaseModel] | None:
        """Get the Pydantic validator model for a given S3 object name."""
        for pattern, validator in SCHEMA_VALIDATORS.items():
            if s3_object_name.endswith(pattern):
                return validator
        return None

    def _validate_json_data(
        self, json_data: dict[str, Any], validator: type[BaseModel],
    ) -> bool:
        """Validate JSON data against a Pydantic model. Returns True if valid."""
        try:
            validator.model_validate(json_data)
        except ValidationError:
            self.logger.exception("Validation failed")
            return False
        else:
            return True

    def upload_json_file(self, local_file_path: str, s3_object_name: str) -> bool:
        """Upload a JSON file to S3 bucket. Return if the upload was successful.

        Validates the JSON data against the appropriate Pydantic model before uploading.
        """
        validator = self._get_validator(s3_object_name)

        if validator:
            try:
                with Path(local_file_path).open(encoding="utf-8") as f:
                    json_data = json.load(f)
            except Exception:
                self.logger.exception(
                    "Error loading JSON file %s",
                    local_file_path,
                )
                return False

            if not self._validate_json_data(json_data, validator):
                self.logger.error(
                    "Validation failed for %s, not uploading", local_file_path,
                )
                return False

        try:
            self._client.fput_object(
                self.BUCKET_NAME,
                s3_object_name,
                local_file_path,
                content_type="application/json",
            )
        except Exception:
            self.logger.exception(
                "Error uploading %s to %s",
                local_file_path,
                s3_object_name,
            )
            return False

        return True

    def get_json_file(self, s3_object_name: str) -> dict[str, Any] | None:
        """Get JSON data from S3 bucket."""
        try:
            # Get the object
            response = self._client.get_object(self.BUCKET_NAME, s3_object_name)

            # Read and parse JSON data
            json_data = json.loads(response.read().decode("utf-8"))

        except Exception:
            self.logger.exception(
                "Error getting %s from %s",
                s3_object_name,
                self.BUCKET_NAME,
            )
            return None

        return cast("dict[str, Any]", json_data)


if __name__ == "__main__":
    s3_client = S3Client()
    json_data = s3_client.get_json_file("floorplans/buildings.json")
